{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Net 000001EACF28FB30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ref :https://github.com/ProGamerGov/Torch-Models\n",
    "#ref :https://www.pyimagesearch.com/2018/08/27/neural-style-transfer-with-opencv/\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "net = cv2.dnn.readNetFromTorch('static/models/' + 'pink_style_1800.t7')\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image, resize it to have a width of 600 pixels, and\n",
    "# then grab the image dimensions\n",
    "#give image location\n",
    "image = cv2.imread('bhawna.jpg')\n",
    "image = imutils.resize(image, width=600)\n",
    "(h, w) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 61.28626   ,  68.0465    ,  75.12886   , ...,  25.655518  ,\n",
       "           17.232075  ,  14.18674   ],\n",
       "         [ 73.838486  ,  79.12394   ,  87.427155  , ...,  32.46025   ,\n",
       "           20.520922  ,  16.968124  ],\n",
       "         [ 82.26194   ,  85.168846  ,  90.79968   , ...,  29.336973  ,\n",
       "           17.613419  ,  13.566157  ],\n",
       "         ...,\n",
       "         [ 20.391842  ,  27.224869  ,  31.519451  , ...,  12.899268  ,\n",
       "            9.897596  ,   8.915797  ],\n",
       "         [ 18.519781  ,  18.810719  ,  19.875822  , ...,   8.494356  ,\n",
       "            6.902215  ,   3.544262  ],\n",
       "         [ 47.542107  ,  59.992813  ,  61.89514   , ...,  15.987897  ,\n",
       "           12.782725  ,   6.890907  ]],\n",
       "\n",
       "        [[ 34.930573  ,  32.616795  ,  38.658264  , ...,  15.16345   ,\n",
       "            9.996386  ,  11.844824  ],\n",
       "         [ 45.013508  ,  39.64367   ,  48.695885  , ...,  18.431618  ,\n",
       "           12.436331  ,  11.6353    ],\n",
       "         [ 47.65616   ,  40.539898  ,  43.146324  , ...,  13.738152  ,\n",
       "            9.035755  ,   9.975403  ],\n",
       "         ...,\n",
       "         [ 32.56517   ,  39.03539   ,  52.99244   , ...,   0.8914412 ,\n",
       "           -1.518098  ,   9.945166  ],\n",
       "         [ 19.920336  ,  20.860157  ,  34.20269   , ...,  -6.857562  ,\n",
       "            0.16236131,   4.4905715 ],\n",
       "         [ 41.090553  ,  54.888447  ,  64.46659   , ...,   8.58179   ,\n",
       "            7.071828  ,   6.3180437 ]],\n",
       "\n",
       "        [[ -3.4676425 ,  -4.4877295 ,  -4.7643747 , ..., -24.379007  ,\n",
       "          -12.076379  ,  -6.8312826 ],\n",
       "         [ -6.597321  , -11.031673  , -11.819106  , ..., -30.925007  ,\n",
       "          -17.407547  ,  -7.7098045 ],\n",
       "         [ -4.120739  , -15.703811  , -19.510593  , ..., -31.237326  ,\n",
       "          -16.865585  ,  -7.712928  ],\n",
       "         ...,\n",
       "         [ 36.179657  ,  41.220654  ,  52.929653  , ...,   3.247089  ,\n",
       "            1.443602  ,   9.82483   ],\n",
       "         [ 16.008617  ,  11.470446  ,  18.787022  , ...,  -7.4432893 ,\n",
       "           -1.6230923 ,  -0.88816845],\n",
       "         [ 38.364166  ,  47.12363   ,  51.974304  , ...,   9.217318  ,\n",
       "           11.371552  ,   8.6070175 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a blob from the image, set the input, and then perform a\n",
    "# forward pass of the network\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (w, h), (103.939, 116.779, 123.680), swapRB=False, crop=False)\n",
    "net.setInput(blob)\n",
    "\n",
    "output = net.forward()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then swap the channel ordering\n",
    "output = output.reshape((3, output.shape[2], output.shape[3]))\n",
    "output[0] += 103.939\n",
    "output[1] += 116.779\n",
    "output[2] += 123.680\n",
    "#uncomment this for imshow etc to display (if running as a script)\n",
    "output /= 255.0\n",
    "output = output.transpose(1, 2, 0)\n",
    "\n",
    "cv2.imshow('image',output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
